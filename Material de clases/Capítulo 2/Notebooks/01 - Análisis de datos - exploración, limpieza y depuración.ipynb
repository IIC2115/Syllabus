{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DGxYp26darl3"
      },
      "source": [
        "<p>\n",
        "<font size='5' face='Georgia, Arial'>IIC2115 - Programación como herramienta para la ingeniería</font><br>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A8_uhtsarl4"
      },
      "source": [
        "# Análisis de datos en Python\n",
        "\n",
        "## ¿Qué es la ciencia de datos?\n",
        "La ciencia de datos es una disciplina altamente popular en la actualidad, que puede verse como el nombre o la etiqueta para un conjunto interdisciplinario de habilidades que se están volviendo cada vez más importantes en muchas aplicaciones en toda la industria y la academia. Esta comprende principalmente tres áreas distintas y superpuestas: las habilidades estadísticas para modelar y resumir conjuntos de datos (que son cada vez más grandes); las habilidades computacionales que para diseñar y usar algoritmos para almacenar, procesar y visualizar eficientemente estos datos; y la experiencia en el dominio, la que podríamos considerar la \"formación clásica\" en un tema, necesaria tanto para formular las preguntas correctas como para poner sus respuestas en un contexto adecuado. Con esto último en mente, podemos considerar a la ciencia de datos no como un nuevo dominio de conocimiento para aprender, sino como un nuevo conjunto de habilidades que puede aplicar dentro de su área de especialización actual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbFVSRnQarl5"
      },
      "source": [
        "## ¿Por qué usar Python para analizar datos?\n",
        "\n",
        "Python ha surgido en las última décadas como una de las herramientas principales para tareas de computación científica, incluido el análisis y la visualización de grandes conjuntos de datos. Esto puede haber sido una sorpresa para los desarrolladores originales del lenguaje, ya que este no fue en si diseñado específicamente con el análisis de datos o la computación científica en mente.\n",
        "\n",
        "La utilidad de Python para el análisis de datos proviene principalmente del ecosistema grande y activo de módulos desarrollados por terceros. En particular, los siguientes módulos son los más populares y serán cubiertos (con distinto nivel de profundidad) en este capítulo y el siguiente:\n",
        "\n",
        "* NumPy: es una módulo para la manipulación de datos de tipo homogéneo basados en arreglos. Contiene, entre otras cosas, tipos de datos especializados para almacenar matrices, funciones básicas de álgebra lineal, y capacidades avanzadas de generación de números aleatorios.\n",
        "* Pandas: es un módulo que permite realizar operaciones sobre datos estructurados heterogéneos. Se usa ampliamente para la manipulación y preparación de datos.\n",
        "* Matplotlib y Seaborn: módulos que permiten generar una gran variedad de gráficos de alta calidad, desde histogramas hasta mapas de calor.\n",
        "* Scikit Learn: es un módulo contiene una gran cantidad de herramientas para aprendizaje de máquina y el modelamiento estadístico. Incluye entre otras cosas algoritmos para clasificación, regresión, clustering y reducción de dimensionalidad.\n",
        "\n",
        "Uniendo todos estos módulos se encuentran IPython y los Notebooks, que permiten la ejecución interactiva de scripts en Python y el uso compartido de código, aspectos claves para realizar exitosamente análisis exploratorios sobre los datos.\n",
        "\n",
        "Es muy recomendable complementar este capítulo del curso con la búsqueda de información sobre estos módulo en internet, con el fin de solucionar excepciones, entender mejor su funcionamiento y cómo instalarlas en nuestro entorno de desarrollo. Muchas ya se encuentran instaladas y vienen por defecto en Python, pero otras hay que instalar manualmente para que funcionen."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OnvbCiSParl5"
      },
      "source": [
        "## El proceso de análisis de datos\n",
        "\n",
        "Ahora que estamos familiarizados con los nombres y objetivos de las bibliotecas adicionales, realizaremos una revisión de la resolución de problemas de datos a través de Python. En particular, este proceso nos llevará por las siguientes 3 etapas claves:\n",
        "\n",
        "* Análisis exploratorio\n",
        "* Limpieza y depuración\n",
        "* Construcción de modelos predictivos\n",
        "\n",
        "Este capítulo se centrará en las primeras dos etapas, análisis exploratorio, y limpieza y depuración, mientas que en el siguiente capítulo revisaremos la construcción de modelos predictivos utilizando aprendizaje de máquina (_machine learning_)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYfw8GKgarl5"
      },
      "source": [
        "## Análisis exploratorio\n",
        "\n",
        "Para esta etapa del proceso, utiliaremos la librería Pandas. En particular, la utilizaremos para leer un conjunto de datos y realizar un análisis exploratorio.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJQVF2tfarl5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iqAzIeparl6"
      },
      "source": [
        "Antes de cargar los datos, vamos a describir las 2 estructuras de datos clave en Pandas: Series y DataFrames\n",
        "\n",
        "**Series** se puede entender como un arreglo unidimensional etiquetado/indexado. Se puede acceder a elementos individuales de esta Serie a través de estas etiquetas.\n",
        "\n",
        "**DataFrame** es similar a un libro de Excel, tiene nombres de columnas que hacen referencia a ellas y tiene filas, a las que se puede acceder mediante el uso de números de estas. La diferencia esencial es que acá, los nombres de columna y los números de fila se conocen como índice de columna y fila.\n",
        "\n",
        "Series y DataFrames forman el modelo de datos básicos para Pandas en Python. Los conjuntos de datos se leen primero en DataFrames y luego se pueden aplicar fácilmente varias operaciones (por ejemplo, agrupar por, agregación, etc.) a sus columnas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umyKLHXMarl6"
      },
      "source": [
        "Utilizaremos para el ejemplo un set de datos de información de créditos bancarios que se encuentra en el archivo `data.csv`. Para importarlo, basta con utilizar la función *read_csv()*:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3h3rD5Jarl6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as mpl\n",
        "from IPython.display import display #para mostrar más de un elemento por celda de Jupyter\n",
        "\n",
        "df = pd.read_csv(\"data.csv\")\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8AcCagE1arl6"
      },
      "source": [
        "La función `describe()` proporciona el conteo, media, desviación, mínimo, cuartiles y máximo de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HEglJzf5arl7"
      },
      "outputs": [],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y0-6jSSzarl7"
      },
      "source": [
        "A continuación algunas aspectos que pueden deducirse de esta información:\n",
        "\n",
        "* LoanAmount tiene (614-592) 22 valores perdidos.\n",
        "* Loan_Amount_Term tiene (614-600) 14 valores faltantes.\n",
        "* Credit_History tiene (614-564) 50 valores perdidos.\n",
        "* También podemos observar que alrededor del 84% de los solicitantes tienen un historial crediticio (la media del campo Credit_History es 0.84).\n",
        "\n",
        "Para los valores no numéricos (por ejemplo, Property_Area, Credit_History, etc.), podemos ver la distribución de frecuencias para comprender si tienen sentido o no. La tabla de frecuencias se puede imprimir con el siguiente comando:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMl27U0Narl7"
      },
      "outputs": [],
      "source": [
        "property_area = df['Property_Area']\n",
        "display(property_area)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGUFvZN6arl7"
      },
      "outputs": [],
      "source": [
        "property_area.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMB5WlDarl7"
      },
      "source": [
        "Del mismo modo, podemos mirar los valores únicos del historial de crédito. Es importante tener en cuenta que `df['columna']` es una técnica de indexación básica para acceder a una columna particular del DataFrame. Puede ser una lista de columnas también."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qY0_q8y5arl7"
      },
      "source": [
        "### Análisis distribucional\n",
        "\n",
        "Ahora que estamos familiarizados con las características básicas de los datos, estudiemos la distribución de algunas de sus variables. Comencemos con las variables numéricas `ApplicantIncome` y `LoanAmount`, en particular, con el histograma de `ApplicantIncome` usando los siguientes comandos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtIeBngRarl7",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "df['ApplicantIncome'].hist(bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7sTdxAyarl7"
      },
      "source": [
        "Aquí observamos que hay algunos valores extremos. Esta es también la razón por la cual se requieren 50 _bins_ para representar claramente la distribución.\n",
        "\n",
        "A continuación, revisaremos Box Plots para comprender las distribuciones:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WoDVon8Tarl7"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column = 'ApplicantIncome')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pprjl0tarl7"
      },
      "source": [
        "Esto gráfico indica la presencia de valores extremos más claramente que el histograma. Esto se puede atribuir a la disparidad de ingresos en la sociedad. Parte de esto puede ser impulsado por el hecho de que estamos viendo personas con diferentes niveles de educación:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P3CkuSXFarl7"
      },
      "outputs": [],
      "source": [
        "df.boxplot(column='ApplicantIncome', by = 'Education')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PLUkV65arl7"
      },
      "source": [
        "Podemos ver que no hay diferencias sustanciales entre los ingresos medios de los graduados y los no graduados. Pero hay un mayor número de graduados con ingresos muy altos, que parecen ser los valores atípicos.\n",
        "\n",
        "Ahora, veamos el histograma y el Box Plot de `LoanAmount`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AXb4flharl7"
      },
      "outputs": [],
      "source": [
        "df['LoanAmount'].hist(bins=50)\n",
        "plt.show()\n",
        "df.boxplot(column='LoanAmount')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJ7Ge8sGarl7"
      },
      "source": [
        "Nuevamente hay valores extremos. Con el fin de facilitar el posterior modelamiento predictivo, tanto `ApplicantIncome` como `LoanAmount` requieren una cierta cantidad de depuración de datos (los valores extremos son difíciles de predecir). `LoanAmount` tiene además valores incompletos y también extremos, mientras que `ApplicantIncome` tiene algunos valores extremos, que exigen una comprensión más profunda. Continuaremos con el análisis de estas variables más adelante. A continuación revisaremos el análisis de variables categóricas. Pero antes..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ZN787dAarl7"
      },
      "source": [
        "### Interludio: funciones lambda\n",
        "Las funciones `lambda` son una forma alternativa de definir funciones en Python. Veamos un ejemplo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xODQehMqarl8"
      },
      "outputs": [],
      "source": [
        "sumar_uno = lambda x: x+1\n",
        "\n",
        "#es (casi) equivalente a\n",
        "\n",
        "def sumar_uno(x):\n",
        "    return x+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfM8pKo-arl8"
      },
      "outputs": [],
      "source": [
        "#para que el gráfico se genere dentro del notebook y no en una ventana aparte\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "gauss = lambda x, mu, sigma: (1./(np.sqrt(2*np.pi)*sigma)) * np.exp(-0.5*((x - mu)/sigma)**2)\n",
        "\n",
        "mu = 0.\n",
        "sigma = 0.2\n",
        "x = np.linspace(-2,2,300)\n",
        "plt.plot(x, gauss(x, mu, sigma), '-r')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bIXpvWpIarl8"
      },
      "source": [
        "Además de lo anterior, las funciones `lambda` pueden ser definidas de forma anónima; es decir, funciones que no tienen nombre. Estas funciones pueden ser vistas como _fugaces_ y son utilizadas únicamente donde fueron creadas. Esta anonimidad se combina bien con las funciones que veremos a continuación: `map`, `filter`, `reduce`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qApc1uRmarl8"
      },
      "source": [
        "#### `map`\n",
        "\n",
        "La función `map` aplica, en esencia, una misma función a todos los elementos de un objeto iterable (lista, diccionario, set, etc.). Recibe como parámetros una función y al menos un objeto iterable. Retorna un generador que resulta de aplicar la función sobre el iterable. `map(f, iterable)` es equivalente a `(f(x) for x in iterable)`\n",
        "\n",
        "La cantidad de iterables entregada a `map` debe corresponder con la cantidad de parámetros que recible la función `f`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LBwiwgkaarl8"
      },
      "outputs": [],
      "source": [
        "pow2 = lambda x : x**2\n",
        "t = np.linspace(-1.,1., 100)#crea un arreglo numpy de 100 elementos, partiendo desde -1 y llegando a 1\n",
        "plt.plot(t, list(map(pow2, t)), '-b')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56chqHGHarl8"
      },
      "source": [
        "Map puede ser aplicado también en más de una lista:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0yzjXBbarl8"
      },
      "outputs": [],
      "source": [
        "a = [1, 2, 3, 4]\n",
        "b = [17, 12, 11, 10]\n",
        "c = [-1, -4, 5, 9]\n",
        "\n",
        "c1 = list(map(lambda x, y: x + y, a, b))\n",
        "\n",
        "c2 = list(map(lambda x, y, z: x + y + z, a, b, c))\n",
        "\n",
        "c3 = list(map(lambda x, y, z: 2.5*x + 2*y - z, a, b, c))\n",
        "\n",
        "print(c1)\n",
        "print(c2)\n",
        "print(c3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm-3wWVNarl8"
      },
      "source": [
        "#### `filter`   \n",
        "\n",
        "`filter(f, secuencia)` retorna el resultado de aplicar la función `f` a `secuencia`, dejando fuera los datos en que el resultado de aplicar `f` al elemento fue `False`. La función `f` **debe** retornar un valor de tipo booleano."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dc_Q6mm5arl8"
      },
      "outputs": [],
      "source": [
        "def fibonacci(n):\n",
        "    a,b = 0,1\n",
        "    values = []\n",
        "    for i in range(1,n):\n",
        "        values.append(b)\n",
        "        a, b = b, a + b\n",
        "    return values\n",
        "\n",
        "fib = fibonacci(11)\n",
        "impares = list(filter(lambda x: x % 2 != 0, fib))\n",
        "print(impares)\n",
        "\n",
        "pares = list(filter(lambda x: x % 2 == 0, fib))\n",
        "print(pares)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p7R0W7sparl8"
      },
      "source": [
        "#### `reduce`\n",
        "\n",
        "`reduce(f, [s1,s2,s3,...,sn])` retorna lo que resulta de aplicar la función `f` a la secuencia `[s1, s2, s3, ..., sn]` de la siguiente forma: `f(f(f(f(s1,s2),s3),s4),s5),...`  ![](https://github.com/IIC2115/Syllabus-2025-1/blob/main/Material%20de%20clases/Cap%C3%ADtulo%202/Notebooks/figs/reduce.png?raw=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZOwSFbcarl8"
      },
      "outputs": [],
      "source": [
        "from functools import reduce\n",
        "reduce(lambda x, y: x+y, range(1,10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0GQI5BVcarl8"
      },
      "source": [
        "### Análisis de variables categóricas\n",
        "\n",
        "Ahora que conocemos las distribuciones para `ApplicantIncome` y `LoanIncome`, analicemos las variables categóricas en más detalle. Utilizaremos tablas dinámicas tipo Excel y tabulación cruzada. Es importante notar que aquí el estado del préstamo ha sido codificado como 1 para sí y 0 para no. Por lo tanto, la media representa la probabilidad de obtener un préstamo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ceGBoExYarl8"
      },
      "outputs": [],
      "source": [
        "temp1 = df['Credit_History'].value_counts(ascending=True)\n",
        "print('Tabla de frecuencia para el historial de crédito:')\n",
        "print(temp1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9LEDeyIyarl8"
      },
      "outputs": [],
      "source": [
        "#la función map que aparece a continuación no es la que vimos anteriormente. esta es de pandas y no funciona igual.\n",
        "temp2 = df.pivot_table(values='Loan_Status',index=['Credit_History'],aggfunc = lambda x: x.map({'Y':1,'N':0}).mean())\n",
        "print('\\nProbabilidad de obtener un crédito, en base a la existencia de historial crediticio:')\n",
        "print(temp2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_43eIqSarmD"
      },
      "source": [
        "Estas mismas tablas se pueden mostrar como un gráfico de barras usando la biblioteca *matplotlib* con el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1ISjo80armD"
      },
      "outputs": [],
      "source": [
        "ax1 = temp1.plot(kind='bar')\n",
        "ax1.set_xlabel('Credit_History')\n",
        "ax1.set_ylabel('Count of Applicants')\n",
        "ax1.set_title(\"Applicants by Credit_History\")\n",
        "\n",
        "\n",
        "ax2 = temp2.plot(kind = 'bar')\n",
        "ax2.set_xlabel('Credit_History')\n",
        "ax2.set_ylabel('Probability of getting loan')\n",
        "ax2.set_title(\"Probability of getting loan by credit history\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNnqE45qarmD"
      },
      "source": [
        "Esto muestra que las posibilidades de obtener un préstamo son ocho veces mayores si el solicitante tiene un historial crediticio válido.\n",
        "\n",
        "Alternativamente, estos dos gráficos también se pueden visualizar combinándolos en un gráfico apilado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tejbXLsiarmD"
      },
      "outputs": [],
      "source": [
        "temp3 = pd.crosstab(df['Credit_History'], df['Loan_Status'])\n",
        "temp3.plot(kind='bar', stacked=True, color=['red','blue'], grid=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRyHub4xarmD"
      },
      "source": [
        "También es posible agregar la información de género:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zkaLUV-AarmD"
      },
      "outputs": [],
      "source": [
        "temp4 = pd.crosstab([df['Credit_History'],df['Gender']], df['Loan_Status'])\n",
        "temp4.plot(kind='bar', stacked=True, color=['red','blue'], grid=False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xg1KuhRearmD"
      },
      "source": [
        "Acabamos de ver cómo podemos hacer un análisis exploratorio en Python usando Pandas, lo que nos entregó información relevante que será utilizada en la siguiente etapa."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dz3RdlRJarmD"
      },
      "source": [
        "## Limpieza y depuración de los datos\n",
        "\n",
        "Mientras exploramos los datos, encontramos algunos problemas en estos, que deben resolverse antes de realizar análisis posteriores (por ej., construir un modelo predictivo). Aquí algunos de los problemas de los que ya somos conscientes:\n",
        "\n",
        "* Faltan valores en algunas variables.\n",
        "* Al observar las distribuciones, vimos que ApplicantIncome y LoanAmount parecían contener valores extremos.\n",
        "\n",
        "Además de estos problemas con los campos numéricos, también debemos ver los campos no numéricos, es decir, Género, Área de la propiedad, Casado, Educación y Dependientes para ver, si contienen información útil o incompleta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-GKu0tKaarmD"
      },
      "source": [
        "### Verificación de los valores faltantes\n",
        "\n",
        "Echemos un vistazo a los valores faltantes en todas las variables:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpXRY_aaarmD"
      },
      "outputs": [],
      "source": [
        "df.apply(lambda x: sum(x.isnull()),axis=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XupWl5Z_armD"
      },
      "source": [
        "Aunque los valores perdidos no son muy altos en número, muchas variables los tienen y cada uno de ellos debe estimarse y agregarse en los datos. Es importante tener en cuenta que los valores perdidos pueden no ser siempre NaN o null."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9klxA4SxarmD"
      },
      "source": [
        "### ¿Cómo completar los valores perdidos en LoanAmount?\n",
        "\n",
        "Existen numerosas formas de completar los valores faltantes del monto del préstamo, siendo el más simple el reemplazo por la media, que se puede hacer mediante el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLBBDTiHarmD"
      },
      "outputs": [],
      "source": [
        "df['LoanAmount'] = df['LoanAmount'].fillna(df['LoanAmount'].mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RVAFabfKarmE"
      },
      "source": [
        "Podemos tomar otro enfoque a través del siguiente proceso. Primero, veamos el Box Plot para ver si existe una tendencia:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pWTM6snZarmE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"data.csv\")\n",
        "df.boxplot(column='LoanAmount', by = ['Education','Self_Employed'])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgYLvk3KarmE"
      },
      "source": [
        "Es posible apreciar algunas variaciones en la mediana del monto del préstamo para cada grupo y esto puede usarse para llenar los valores faltantes. Pero primero, debemos asegurarnos de que cada una de las variables de Self_Employed y Education no debe tener valores perdidos. Veamos la tabla de frecuencias:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO6c2-jdarmE"
      },
      "outputs": [],
      "source": [
        "df['Self_Employed'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUKtLmLqarmE"
      },
      "source": [
        "Como aproximadamente 86% de los valores son \"No\", es seguro llenar los valores faltantes como \"No\", ya que hay una alta probabilidad de éxito. Esto se puede hacer usando el siguiente código:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qw_uNcNnarmE"
      },
      "outputs": [],
      "source": [
        "df['Self_Employed'] = df['Self_Employed'].fillna('No')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eeiz7qCarmE"
      },
      "source": [
        "Ahora, crearemos una tabla dinámica, que nos proporciona valores medios para todos los grupos de valores únicos de las características `Self_Employed` y `Education`. A continuación, definimos una función, que devuelve los valores de estas celdas y la aplica para completar los valores que faltan del monto del préstamo:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BHQp2Wj_armE"
      },
      "outputs": [],
      "source": [
        "table = df.pivot_table(values='LoanAmount', index='Self_Employed' ,columns='Education', aggfunc=\"median\")\n",
        "print(table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFw2DxhAarmE"
      },
      "outputs": [],
      "source": [
        "def fage(x):\n",
        "    return table.loc[x['Self_Employed'],x['Education']]\n",
        "\n",
        "df[df['LoanAmount'].isnull()].apply(fage, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gAgJbP9carmE"
      },
      "outputs": [],
      "source": [
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kcdBmdgarmE"
      },
      "outputs": [],
      "source": [
        "df['LoanAmount'] = df['LoanAmount'].fillna(df[df['LoanAmount'].isnull()].apply(fage, axis=1))\n",
        "table.plot(kind='bar')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGmTXtrharmE"
      },
      "outputs": [],
      "source": [
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMAg9i_9armE"
      },
      "source": [
        "### ¿Cómo tratar los valores extremos?\n",
        "\n",
        "A continuación se presenta una de muchas maneras de tratar los valores extremos. Analicemos LoanAmount primero. Dado que los valores extremos seguramente no se deben a un error, es factible que algunas personas soliciten préstamos de alto valor debido a necesidades específicas. Entonces, en lugar de tratarlos como valores atípicos, probemos una transformación logarítmica para anular su efecto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8vUXCtzarmE"
      },
      "outputs": [],
      "source": [
        "df['LoanAmount_log'] = np.log(df['LoanAmount'])\n",
        "df['LoanAmount_log'].hist(bins=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTR3REqmarmE"
      },
      "source": [
        "Ahora la distribución se ve mucho más cerca de una normal (preferible para muchos modelos predictivos) y el efecto de los valores extremos ha disminuido significativamente.\n",
        "\n",
        "Ahora, en relación a `ApplicantIncome`, una intuición puede ser que algunos solicitantes tienen un ingreso más bajo, pero tiene avales fuertes. Por lo tanto, podría ser una buena idea combinar ambos ingresos como ingreso total y tomar una transformación de este valor:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LGKf19y6armE"
      },
      "outputs": [],
      "source": [
        "df['TotalIncome'] = df['ApplicantIncome'] + df['CoapplicantIncome']\n",
        "df['TotalIncome_log'] = np.log(df['TotalIncome'])\n",
        "df['TotalIncome_log'].hist(bins=20)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e6jWg8SlarmE"
      },
      "source": [
        "Ahora vemos que la distribución es mucho más \"normal\" que antes."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
